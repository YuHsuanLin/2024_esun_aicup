from modules.es_client import ElasticsearchClient
from modules.llm_client import LLMClient
from modules.embedding_client import EmbeddingClient
from modules.rerank_client import RerankClient

from llama_index.core.node_parser import SentenceSplitter

from typing import List, Optional, Dict
import argparse
import time
import json
import sys

from config import ES_INDEX_NAME as DEFAULT_INDEX_NAME

class SearchEngine:
    def __init__(self, llm_provider: str = "openai", rerank_mode: str = 'fast_rerank', index_name: str = DEFAULT_INDEX_NAME):
        print("åˆå§‹åŒ–æœç´¢å¼•æ“çµ„ä»¶...")
        try:
            self.es_client = ElasticsearchClient()
            self.llm_client = LLMClient(provider=llm_provider)
            self.embedding_client = EmbeddingClient()
            self.rerank_client = RerankClient(mode=rerank_mode, llm_provider=llm_provider)
            self.index_name = index_name
            print("âœ“ æ‰€æœ‰çµ„ä»¶åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def index_documents(self, documents: List[Dict], batch_size: int = 5, chunk_size: int = 512, chunk_overlap: int = 50, use_chunk: bool = True) -> None:
        """æ‰¹é‡ç´¢å¼•æ–‡æª”ï¼Œæ”¯æŒæ»‘åŠ¨çª—å£åˆ†å—"""
        """
        documents = [
            {'id': '1', 'text': 'é€™æ˜¯ç¬¬ä¸€å€‹æ–‡æª”', 'category': 'category1'},
            {'id': '2', 'text': 'é€™æ˜¯ç¬¬äºŒå€‹æ–‡æª”', 'category': 'category2'},
            {'id': '3', 'text': 'é€™æ˜¯ç¬¬ä¸‰å€‹æ–‡æª”', 'category': 'category3'},
        ]
        """

        total = len(documents)
        print(f"\né–‹å§‹ç´¢å¼• {total} å€‹æ–‡æª”...")

        splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
        
        for idx, doc in enumerate(documents):
            try:
                
                # ä½¿ç”¨æ»‘åŠ¨çª—å£åˆ†å—æ–‡æ¡£
                text = doc.get('text')
                category = doc.get('category')
                doc_id = doc.get('id')

                print(f"[{idx}/{total}] è™•ç†æ–‡æª”...")

                if use_chunk:    
                    chunks = splitter.split_text(text)
                    for chunk_index, chunk in enumerate(chunks):
                        embeddings = self.embedding_client.get_embedding(chunk)
                        # å°‡ doc_id è½‰ç‚ºå­—ç¬¦ä¸²ï¼Œchunk_index ä½œç‚º sn
                        self.es_client.index_document(
                            doc_id=str(doc_id),
                            sn=chunk_index,
                            category=category,
                            content=chunk,
                            embedding=embeddings,
                            index_name=self.index_name,
                        )
                else:
                    sn = doc.get('sn', 0)
                    embeddings = self.embedding_client.get_embedding(text)
                    self.es_client.index_document(
                        doc_id=str(doc_id),
                        sn=sn,
                        category=category,
                        content=text,
                        embedding=embeddings,
                        index_name=self.index_name,
                    )

                print(f"âœ“ å·²å®Œæˆ {idx}/{total} å€‹æ–‡æª”çš„ç´¢å¼•")
                # time.sleep(0.5)  # é¿å…è¶…éAPIé™åˆ¶
                
            except Exception as e:
                print(f"âŒ ç´¢å¼•æ–‡æª” {doc_id} æ™‚å‡ºéŒ¯: {e}")
                
        print(f"\nâœ“ ç´¢å¼•å®Œæˆï¼Œå…±è™•ç† {total} å€‹æ–‡æª”")

    def retrieve(
        self,
        query: str,
        category: str = None,
        doc_ids: List[str] = [],
        top_k: int = 3,
        knn_weight: float = 0.7,
        rerank_k: int = 10,
        use_rerank: bool = True,  # æ–°å¢åƒæ•¸
    ) -> List[str]:
        """åŸ·è¡Œæœç´¢æµç¨‹"""
        try:
            print(f"\n[1/4] é–‹å§‹æ··åˆæœç´¢æµç¨‹ - æŸ¥è©¢: '{query}'")
            
            print(f"[2/4] ç”ŸæˆæŸ¥è©¢çš„åµŒå…¥å‘é‡...")
            query_vector = self.embedding_client.get_embedding(query)
            
            search_size = rerank_k if use_rerank else top_k
            print(f"[3/4] åŸ·è¡ŒElasticsearchæ··åˆæœç´¢ (æª¢ç´¢ {search_size} å€‹å€™é¸æ–‡æª”)...")
            candidates = self.es_client.hybrid_search(query, query_vector, search_size, category, doc_ids, knn_weight, index_name = self.index_name)
            
            if not candidates:
                print("âŒ æœªæ‰¾åˆ°ç›¸é—œæ–‡æª”")
                return []
                
            print(f"âœ“ æ‰¾åˆ° {len(candidates)} å€‹å€™é¸æ–‡æª”")
            
            if use_rerank:
                print(f"[4/4] é‡æ–°æ’åºçµæœ...")
                candidates_content = [
                    {
                        'id': candidate.get('_source', {}).get('doc_id'),
                        'content': candidate.get('_source', {}).get('content')
                    } for candidate in candidates
                ]

                results = self.rerank_client.rerank(
                    query,
                    candidates_content,
                    top_k=top_k,
                )
                print(f"âœ“ å®Œæˆé‡æ’åºï¼Œè¿”å›å‰ {top_k} å€‹çµæœ")
            else:
                print("[4/4] è·³éé‡æ’åºæ­¥é©Ÿ...")
                results = [
                    {
                        'id': candidate.get('_source', {}).get('doc_id'),
                        'content': candidate.get('_source', {}).get('content')
                    } for candidate in candidates[:top_k]
                ]
                print(f"âœ“ ç›´æ¥è¿”å›å‰ {top_k} å€‹çµæœ")
            
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢éç¨‹å‡ºéŒ¯: {e}")
            return []

    def generate_response(self, query: str, context: str, doc_ids: List[str]) -> str:
        """ç”Ÿæˆå›æ‡‰"""
        return {
            'response': self.llm_client.generate_response(query, context),
            'retrieved_docs': doc_ids,
        }

def load_documents(file_path: str) -> List[str]:
    """å¾æ–‡ä»¶åŠ è¼‰æ–‡æª”"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ è®€å–æ–‡æª”æ–‡ä»¶æ™‚å‡ºéŒ¯: {e}")
        return []

def setup_argparse() -> argparse.ArgumentParser:
    """è¨­ç½®å‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(
        description='RAG æœç´¢å¼•æ“ - ä¸€å€‹åŸºæ–¼å‘é‡æœç´¢å’Œèªè¨€æ¨¡å‹çš„æª¢ç´¢å¢å¼·ç³»çµ±',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # ç´¢å¼•æ–‡æª”
  python main.py --mode index --docs documents.json
  
  # æœç´¢æ¨¡å¼ï¼ˆåŒ…å« LLM å›æ‡‰ï¼‰
  python main.py --mode search --query "ä½ çš„å•é¡Œ" --top-k 3
  
  # åƒ…æª¢ç´¢æ¨¡å¼
  python main.py --mode retrieve --query "ä½ çš„å•é¡Œ" --category "åˆ†é¡" --top-k 5
  
  # äº’å‹•æ¨¡å¼
  python main.py --mode interactive
        """
    )
    
    # é‹è¡Œæ¨¡å¼åƒæ•¸çµ„
    mode_group = parser.add_argument_group('é‹è¡Œæ¨¡å¼')
    mode_group.add_argument('--mode', choices=['index', 'retrieve', 'search', 'interactive'],
                           default='interactive', help='é‹è¡Œæ¨¡å¼ (é è¨­: interactive)')
    mode_group.add_argument('--docs', type=str, help='æ–‡æª”JSONæ–‡ä»¶è·¯å¾‘ (åƒ…ç”¨æ–¼ index æ¨¡å¼)')
    mode_group.add_argument('--query', type=str, help='æœç´¢æŸ¥è©¢ (ç”¨æ–¼ search å’Œ retrieve æ¨¡å¼)')
    
    # æœç´¢åƒæ•¸çµ„
    search_group = parser.add_argument_group('æœç´¢åƒæ•¸')
    search_group.add_argument('--category', type=str, default=None, help='æ–‡æª”é¡åˆ¥éæ¿¾ (å¯é¸)')
    search_group.add_argument('--doc_ids', type=str, nargs='+', default=None, help='æ–‡æª”IDåˆ—è¡¨éæ¿¾ (å¯é¸)')
    search_group.add_argument('--top-k', type=int, default=3, help='è¿”å›çµæœæ•¸é‡ (é è¨­: 3)')
    search_group.add_argument('--rerank-k', type=int, default=10, help='é‡æ’åºå€™é¸æ•¸é‡ (é è¨­: 10)')
    search_group.add_argument('--knn-weight', type=float, default=0.7, 
                            help='å‘é‡æœç´¢æ¬Šé‡ (0-1ä¹‹é–“ï¼Œé è¨­: 0.7)')
    
    # æ¨¡å‹åƒæ•¸çµ„
    model_group = parser.add_argument_group('æ¨¡å‹åƒæ•¸')
    model_group.add_argument('--rerank-mode', choices=['fast_rerank', 'llm_rerank'], default='llm_rerank',
                           help='é‡æ’åºæ¨¡å¼ (é è¨­: fast_rerank)')
    model_group.add_argument('--llm-provider', type=str, default='openai',
                           choices=['openai', 'claude'],
                           help='LLM æä¾›å•† (é è¨­: openai)')
    model_group.add_argument('--use-rerank', type=bool, default=True,
                           help='æ˜¯å¦ä½¿ç”¨é‡æ’åº (é è¨­: True)')

    return parser

def interactive_mode(engine: SearchEngine):
    """äº’å‹•æ¨¡å¼"""
    print("\n=== é€²å…¥äº’å‹•æ¨¡å¼ ===")
    print("è¼¸å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    
    while True:
        try:
            query = input("\nè«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: ").strip()
            category = input("è«‹è¼¸å…¥æ–‡æª”é¡åˆ¥: ").strip()
            doc_ids = input("è«‹è¼¸å…¥æ–‡æª”IDåˆ—è¡¨ (ç”¨é€—è™Ÿåˆ†éš”): ").strip().split(',')
            knn_weight = float(input("è«‹è¼¸å…¥å‘é‡æœç´¢æ¬Šé‡ (0-1ä¹‹é–“): "))
            top_k = int(input("è«‹è¼¸å…¥è¿”å›çµæœæ•¸é‡: "))
            
            if query.lower() in ['quit', 'exit']:
                print("è¬è¬ä½¿ç”¨ï¼Œå†è¦‹ï¼")
                break
                
            if not query:
                continue
                
            relevant_docs = engine.retrieve(
                query,
                top_k=top_k,
                rerank_k = 10,
                category=category,
                doc_ids=doc_ids,
                knn_weight=knn_weight,
                use_rerank=True,
            )
            
            if relevant_docs:
                print("\nğŸ“š æ‰¾åˆ°çš„ç›¸é—œæ–‡æª”:")
                for i, doc in enumerate(relevant_docs, 1):
                    print(f"{i}. {doc}")
                
                context = " ".join([doc.get('content') for doc in relevant_docs])
                doc_ids = [doc.get('id') for doc in relevant_docs]

                print("\nğŸ¤– ç”Ÿæˆå›æ‡‰ä¸­...")
                response = engine.generate_response(query, context, doc_ids)
                print(f"\nå›æ‡‰: {response}")
            else:
                print("\nâŒ æœªæ‰¾åˆ°ç›¸é—œæ–‡æª”")
                
        except KeyboardInterrupt:
            print("\n\nå†è¦‹ï¼")
            break
        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

def main():
    parser = setup_argparse()
    args = parser.parse_args()
    
    try:
        engine = SearchEngine(llm_provider=args.llm_provider, rerank_mode=args.rerank_mode)
        
        if args.mode == 'index':
            if not args.docs:
                print("âŒ è«‹æä¾›æ–‡æª”æ–‡ä»¶è·¯å¾‘")
                return
            documents = load_documents(args.docs)
            if documents:
                engine.es_client.create_index_mapping()
                engine.index_documents(documents)
                
        elif args.mode == 'search':
            if not args.query:
                print("âŒ è«‹æä¾›æœç´¢æŸ¥è©¢")
                return
            relevant_docs = engine.retrieve(
                args.query,
                top_k=args.top_k,
                rerank_k=args.rerank_k,
                category=args.category,
                doc_ids=args.doc_ids,
                knn_weight=args.knn_weight,
                use_rerank=args.use_rerank,
            )
            if relevant_docs:
                print("\nğŸ“š æ‰¾åˆ°çš„ç›¸é—œæ–‡æª”:")
                for i, doc in enumerate(relevant_docs, 1):
                    print(f"{i}. {doc.get('content')}")
                    
                context = " ".join([doc.get('content') for doc in relevant_docs])
                doc_ids = [doc.get('id') for doc in relevant_docs]
                print("\nğŸ¤– ç”Ÿæˆå›æ‡‰ä¸­...")
                response = engine.generate_response(args.query, context, doc_ids)
                print(f"\nå›æ‡‰: {response}")

        elif args.mode == 'retrieve':
            if not args.query:
                print("âŒ è«‹æä¾›æœç´¢æŸ¥è©¢")
                return

            print(f"args: {args}")
            relevant_docs = engine.retrieve(
                args.query,
                top_k=args.top_k,
                rerank_k=args.rerank_k,
                category=args.category,
                doc_ids=args.doc_ids,
                knn_weight=args.knn_weight,
                use_rerank=args.use_rerank,
            )

            print(f"\nğŸ“š æ‰¾åˆ°çš„ç›¸é—œæ–‡æª”:")
            for i, doc in enumerate(relevant_docs, 1):
                print(f"{i}. {doc.get('content')}")
                
        else:  # interactive mode
            interactive_mode(engine)
            
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ä¸­æ–·")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ ç¨‹åºåŸ·è¡Œå‡ºéŒ¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()