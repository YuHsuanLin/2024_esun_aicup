from modules.es_client import ElasticsearchClient
from modules.llm_client import LLMClient
from modules.embedding_client import EmbeddingClient
from modules.rerank_client import RerankClient

from llama_index.core.node_parser import SentenceSplitter

from typing import List, Optional, Dict
import argparse
import time
import json
import sys

class SearchEngine:
    def __init__(self, llm_provider: str = "openai", rerank_mode: str = 'fast_rerank'):
        print("åˆå§‹åŒ–æœç´¢å¼•æ“çµ„ä»¶...")
        try:
            self.es_client = ElasticsearchClient()
            self.llm_client = LLMClient(provider=llm_provider)
            self.embedding_client = EmbeddingClient()
            self.rerank_client = RerankClient(mode=rerank_mode)
            print("âœ“ æ‰€æœ‰çµ„ä»¶åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    def index_documents(self, documents: List[Dict], batch_size: int = 5, chunk_size: int = 512, chunk_overlap: int = 50, use_chunk: bool = True) -> None:
        """æ‰¹é‡ç´¢å¼•æ–‡æª”ï¼Œæ”¯æŒæ»‘åŠ¨çª—å£åˆ†å—"""
        """
        documents = [
            {'id': '1', 'text': 'é€™æ˜¯ç¬¬ä¸€å€‹æ–‡æª”', 'category': 'category1'},
            {'id': '2', 'text': 'é€™æ˜¯ç¬¬äºŒå€‹æ–‡æª”', 'category': 'category2'},
            {'id': '3', 'text': 'é€™æ˜¯ç¬¬ä¸‰å€‹æ–‡æª”', 'category': 'category3'},
        ]
        """

        total = len(documents)
        print(f"\né–‹å§‹ç´¢å¼• {total} å€‹æ–‡æª”...")

        splitter = SentenceSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
        
        for idx, doc in enumerate(documents):
            try:
                
                # ä½¿ç”¨æ»‘åŠ¨çª—å£åˆ†å—æ–‡æ¡£
                text = doc.get('text')
                category = doc.get('category')
                doc_id = doc.get('id')

                print(f"[{idx}/{total}] è™•ç†æ–‡æª”...")

                if use_chunk:    
                    chunks = splitter.split_text(text)
                    for chunk_index, chunk in enumerate(chunks):
                        embeddings = self.embedding_client.get_embedding(chunk)
                        # å°‡ doc_id è½‰ç‚ºå­—ç¬¦ä¸²ï¼Œchunk_index ä½œç‚º sn
                        self.es_client.index_document(
                            doc_id=str(doc_id),
                            sn=chunk_index,
                            category=category,
                            content=chunk,
                            embedding=embeddings
                        )
                else:
                    sn = doc.get('sn', 0)
                    embeddings = self.embedding_client.get_embedding(text)
                    self.es_client.index_document(
                        doc_id=str(doc_id),
                        sn=sn,
                        category=category,
                        content=text,
                        embedding=embeddings
                    )

                print(f"âœ“ å·²å®Œæˆ {idx}/{total} å€‹æ–‡æª”çš„ç´¢å¼•")
                # time.sleep(0.5)  # é¿å…è¶…éAPIé™åˆ¶
                
            except Exception as e:
                print(f"âŒ ç´¢å¼•æ–‡æª” {doc_id} æ™‚å‡ºéŒ¯: {e}")
                
        print(f"\nâœ“ ç´¢å¼•å®Œæˆï¼Œå…±è™•ç† {total} å€‹æ–‡æª”")

    def retrieve(
        self,
        query: str,
        category: str = None,
        top_k: int = 3,
        knn_weight: float = 0.7,
        rerank_k: int = 10,
        rerank_mode: str = "ai",
        use_rerank: bool = True,  # æ–°å¢åƒæ•¸
    ) -> List[str]:
        """åŸ·è¡Œæœç´¢æµç¨‹"""
        try:
            print(f"\n[1/4] é–‹å§‹æ··åˆæœç´¢æµç¨‹ - æŸ¥è©¢: '{query}'")
            
            print(f"[2/4] ç”ŸæˆæŸ¥è©¢çš„åµŒå…¥å‘é‡...")
            query_vector = self.embedding_client.get_embedding(query)
            
            search_size = rerank_k if use_rerank else top_k
            print(f"[3/4] åŸ·è¡ŒElasticsearchæ··åˆæœç´¢ (æª¢ç´¢ {search_size} å€‹å€™é¸æ–‡æª”)...")
            candidates = self.es_client.hybrid_search(query, query_vector, search_size, category, knn_weight)
            
            if not candidates:
                print("âŒ æœªæ‰¾åˆ°ç›¸é—œæ–‡æª”")
                return []
                
            print(f"âœ“ æ‰¾åˆ° {len(candidates)} å€‹å€™é¸æ–‡æª”")
            
            if use_rerank:
                print(f"[4/4] ä½¿ç”¨ {rerank_mode} æ¨¡å¼é‡æ–°æ’åºçµæœ...")
                candidates_content = [
                    {
                        'id': candidate.get('_source', {}).get('doc_id'),
                        'content': candidate.get('_source', {}).get('content')
                    } for candidate in candidates
                ]

                results = self.rerank_client.rerank(
                    query,
                    candidates_content,
                    top_k=top_k,
                    mode=rerank_mode
                )
                print(f"âœ“ å®Œæˆé‡æ’åºï¼Œè¿”å›å‰ {top_k} å€‹çµæœ")
            else:
                print("[4/4] è·³éé‡æ’åºæ­¥é©Ÿ...")
                results = [
                    {
                        'id': candidate.get('_source', {}).get('doc_id'),
                        'content': candidate.get('_source', {}).get('content')
                    } for candidate in candidates[:top_k]
                ]
                print(f"âœ“ ç›´æ¥è¿”å›å‰ {top_k} å€‹çµæœ")
            
            return results
            
        except Exception as e:
            print(f"âŒ æœç´¢éç¨‹å‡ºéŒ¯: {e}")
            return []

    def generate_response(self, query: str, context: str) -> str:
        """ç”Ÿæˆå›æ‡‰"""
        return self.llm_client.generate_response(query, context)

def load_documents(file_path: str) -> List[str]:
    """å¾æ–‡ä»¶åŠ è¼‰æ–‡æª”"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ è®€å–æ–‡æª”æ–‡ä»¶æ™‚å‡ºéŒ¯: {e}")
        return []

def setup_argparse() -> argparse.ArgumentParser:
    """è¨­ç½®å‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(description='RAG æœç´¢å¼•æ“')
    parser.add_argument('--mode', choices=['index', 'search', 'interactive'], 
                       default='interactive', help='é‹è¡Œæ¨¡å¼')
    parser.add_argument('--docs', type=str, help='æ–‡æª”JSONæ–‡ä»¶è·¯å¾‘')
    parser.add_argument('--query', type=str, help='æœç´¢æŸ¥è©¢')
    parser.add_argument('--top-k', type=int, default=3, help='è¿”å›çµæœæ•¸é‡')
    parser.add_argument('--rerank-k', type=int, default=10, help='é‡æ’åºå€™é¸æ•¸é‡')
    parser.add_argument('--rerank-mode', choices=['math', 'ai'], 
                       default='ai', help='é‡æ’åºæ¨¡å¼')
    parser.add_argument('--llm-provider', type=str, default='openai',
                       choices=['openai', 'anthropic', 'google'],
                       help='LLM æä¾›å•†')
    return parser

def interactive_mode(engine: SearchEngine):
    """äº’å‹•æ¨¡å¼"""
    print("\n=== é€²å…¥äº’å‹•æ¨¡å¼ ===")
    print("è¼¸å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    
    while True:
        try:
            query = input("\nè«‹è¼¸å…¥æ‚¨çš„å•é¡Œ: ").strip()
            
            if query.lower() in ['quit', 'exit']:
                print("è¬è¬ä½¿ç”¨ï¼Œå†è¦‹ï¼")
                break
                
            if not query:
                continue
                
            relevant_docs = engine.search(query)
            
            if relevant_docs:
                print("\nğŸ“š æ‰¾åˆ°çš„ç›¸é—œæ–‡æª”:")
                for i, doc in enumerate(relevant_docs, 1):
                    print(f"{i}. {doc}")
                
                context = " ".join(relevant_docs)
                print("\nğŸ¤– ç”Ÿæˆå›æ‡‰ä¸­...")
                response = engine.generate_response(query, context)
                print(f"\nå›æ‡‰: {response}")
            else:
                print("\nâŒ æœªæ‰¾åˆ°ç›¸é—œæ–‡æª”")
                
        except KeyboardInterrupt:
            print("\n\nå†è¦‹ï¼")
            break
        except Exception as e:
            print(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")

def main():
    parser = setup_argparse()
    args = parser.parse_args()
    
    try:
        engine = SearchEngine(llm_provider=args.llm_provider)
        
        if args.mode == 'index':
            if not args.docs:
                print("âŒ è«‹æä¾›æ–‡æª”æ–‡ä»¶è·¯å¾‘")
                return
            documents = load_documents(args.docs)
            if documents:
                engine.es_client.create_index_mapping()
                engine.index_documents(documents)
                
        elif args.mode == 'search':
            if not args.query:
                print("âŒ è«‹æä¾›æœç´¢æŸ¥è©¢")
                return
            relevant_docs = engine.search(
                args.query,
                top_k=args.top_k,
                rerank_k=args.rerank_k,
                rerank_mode=args.rerank_mode
            )
            if relevant_docs:
                print("\nğŸ“š æ‰¾åˆ°çš„ç›¸é—œæ–‡æª”:")
                for i, doc in enumerate(relevant_docs, 1):
                    print(f"{i}. {doc}")
                    
                context = " ".join(relevant_docs)
                print("\nğŸ¤– ç”Ÿæˆå›æ‡‰ä¸­...")
                response = engine.generate_response(args.query, context)
                print(f"\nå›æ‡‰: {response}")
                
        else:  # interactive mode
            interactive_mode(engine)
            
    except KeyboardInterrupt:
        print("\n\nç¨‹åºè¢«ä¸­æ–·")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ ç¨‹åºåŸ·è¡Œå‡ºéŒ¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 